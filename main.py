"""
Enterprise Knowledge Assistant (RAG System)
==========================================

Main pipeline for RAG-based question answering:
- Document ingestion from URLs
- Vector database creation
- Interactive Q&A with Groq AI

This is the main entry point for the knowledge assistant.

Usage:
    python main.py

The system will:
1. Prompt for documentation URLs to ingest
2. Process and chunk the documentation
3. Build vector database for RAG
4. Enter interactive Q&A mode
"""

import os
import sys
import time
from typing import List, Dict

# Add project root to path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# Import all our modules
from ingestion.ingest_docs import process_documentation, get_all_chunks
from rag.retrieval import build_vector_database, get_database_stats
from rag.groq_answering import (
    generate_groq_answer, 
    initialize_groq_generator,
    estimate_tokens,
    remove_code_examples,
    extract_key_sentences,
    smart_truncate
)
from rag.faiss_retrieval import retrieve_relevant_chunks, initialize_vector_store
from rag.answering import get_answer_with_details
from utils.helpers import (
    log_step, format_time_elapsed, validate_url, ensure_directory_exists,
    summarize_file_stats, print_progress_bar
)


class KnowledgeAssistant:
    """
    Main class for the Enterprise Knowledge Assistant.
    
    This class orchestrates document ingestion, vector database creation,
    and provides the Q&A interface.
    """
    
    def __init__(self):
        self.processed_urls = []
        self.vector_db_ready = False
        self.start_time = time.time()
    
    def print_welcome(self):
        """Prints welcome message and system overview."""
        print("=" * 70)
        print("ğŸ¤– ENTERPRISE KNOWLEDGE ASSISTANT")
        print("   RAG System with Groq AI")
        print("   ğŸ†“ FREE Groq API + FAISS + Token Optimization")
        print("=" * 70)
        print()
        print("This system will:")
        print("ğŸ“¥ 1. Ingest documentation from web sources")
        print("ğŸ§  2. Build optimized vector database for Q&A")
        print("ğŸ’¬ 3. Answer your questions using Groq AI (FREE!)")
        print()
        print("ğŸ”§ Technology Stack:")
        print("  ğŸ“Š Vector Store: FAISS with persistent storage")
        print("  ğŸ§  Embeddings: SentenceTransformers (all-MiniLM-L6-v2)")
        print("  ğŸ¤– LLM: Groq Llama-3.1-8B (FREE & FAST!)")
        print("  ğŸ”¤ Token Optimization: 4-step pipeline for FREE tier")
        print("  ğŸ’° Cost: $0.00 - Completely FREE!")
        print()
        print("ğŸ” Grounded answers only - if information isn't in the docs,")
        print("   the system will say: 'The knowledge base does not contain this information.'")
        print()
    
    def get_documentation_urls(self) -> List[str]:
        """
        Gets documentation URLs from user input.
        
        Returns:
            List[str]: List of valid URLs
        """
        print("ğŸ“‹ STEP 1: Documentation URLs")
        print("-" * 40)
        print("Enter documentation URLs to process (one per line).")
        print("Press Enter on empty line to finish.")
        print("Examples:")
        print("  - https://docs.python.org/3/tutorial/")
        print("  - https://docs.python.org/3/library/os.html")
        print()
        
        urls = []
        while True:
            url = input("Enter URL (or press Enter to finish): ").strip()
            
            if not url:  # Empty input, finish
                break
            
            if validate_url(url):
                urls.append(url)
                print(f"âœ… Added: {url}")
            else:
                print(f"âŒ Invalid URL: {url}")
        
        if not urls:
            print("\nğŸ“ No URLs provided. Using sample Python documentation URLs...")
            urls = [
                "https://docs.python.org/3/tutorial/introduction.html",
                "https://docs.python.org/3/tutorial/controlflow.html",
                "https://docs.python.org/3/library/os.html"
            ]
            print("Sample URLs:")
            for url in urls:
                print(f"  - {url}")
        
        return urls
    
    def run_ingestion(self, urls: List[str]) -> bool:
        """
        Runs the document ingestion process.
        
        Args:
            urls (List[str]): URLs to process
            
        Returns:
            bool: True if successful
        """
        log_step("Starting document ingestion", 1)
        start = time.time()
        
        # Ensure data directory exists
        ensure_directory_exists("data")
        
        # Process documentation
        results = process_documentation(urls)
        
        if results:
            self.processed_urls = list(results.keys())
            total_chunks = sum(len(files) for files in results.values())
            
            print(f"\nâœ… Ingestion complete!")
            print(f"   ğŸ“„ Processed: {len(results)} URLs")
            print(f"   ğŸ“¦ Created: {total_chunks} text chunks")
            print(f"   â±ï¸ Time: {format_time_elapsed(start)}")
            
            # Show data directory stats
            stats = summarize_file_stats("data")
            if "error" not in stats:
                print(f"   ğŸ’¾ Storage: {stats['total_size_mb']} MB in {stats['total_files']} files")
            
            return True
        else:
            print("âŒ Ingestion failed - no documents were processed successfully")
            return False
    

    

    
    def build_vector_database(self) -> bool:
        """
        Builds the vector database for RAG.
        
        Returns:
            bool: True if successful
        """
        log_step("Building vector database for RAG", 2)
        start = time.time()
        
        # Ensure rag directory exists
        ensure_directory_exists("rag")
        
        # Initialize FAISS vector store (modern approach)
        print("ğŸ“Š Initializing FAISS vector store...")
        vector_ready = initialize_vector_store()
        
        if not vector_ready:
            print("âŒ Failed to initialize vector database")
            return False
        
        # Initialize Groq system for optimized token handling
        print("ğŸ¤– Initializing Groq AI system...")
        groq_generator = initialize_groq_generator()
        
        if not groq_generator:
            print("âš ï¸ Groq initialization failed - check API key in .env file")
            print("   The system can still work but answers may be limited")
        else:
            print("âœ… Groq AI system ready (FREE tier with token optimization)")
        
        # Build vector database (legacy support)
        success = build_vector_database(force_rebuild=True)
        
        if success:
            self.vector_db_ready = True
            
            # Get database stats
            stats = get_database_stats()
            
            print(f"\nâœ… Vector database built!")
            print(f"   ğŸ§  Documents: {stats.get('total_documents', 0)}")
            print(f"   ğŸ“š Vocabulary: {stats.get('vocabulary_size', 0)} words")
            print(f"   ğŸŒ Sources: {stats.get('unique_sources', 0)} unique URLs")
            print(f"   ğŸ”¤ Token optimization: Enabled (3000 token limit)")
            print(f"   â±ï¸ Time: {format_time_elapsed(start)}")
            
            return True
        else:
            print("âŒ Vector database build failed")
            return False
    
    def show_examples(self):
        """Shows example outputs from all components - DISABLED for cleaner output."""
        # This method is disabled to provide cleaner console output

        pass
    
    def interactive_qa_mode(self):
        """Runs interactive Q&A mode."""
        if not self.vector_db_ready:
            print("âŒ Vector database not ready. Cannot enter Q&A mode.")
            return
        
        print("\n" + "="*70)
        print("ğŸ’¬ INTERACTIVE Q&A MODE")
        print("="*70)
        print("Ask questions about the documentation!")
        print()
        print("Commands:")
        print("  â€¢ 'quit', 'exit', 'q' - Exit the system")
        print("  â€¢ 'summary' - Generate content summary")
        print("  â€¢ 'Give some questions based on the provided content' - faq")
        print("  â€¢ 'stats' - Show usage statistics")
        print("  â€¢ 'debug' - Show token optimization details")
        print("=" * 70)
        
        question_count = 0
        
        while True:
            try:
                question = input("\nâ“ Your question: ").strip()
                
                if not question:
                    continue
                
                # Check for exit commands
                if question.lower() in ['quit', 'exit', 'q']:
                    break
                
                # Generate summary
                if question.lower() == 'summary':
                    self.generate_content_summary()
                    continue
                
                # Show FAQ
                if question.lower() == 'faq':
                    self.show_faq()
                    continue
                
                # Show statistics
                if question.lower() == 'stats':
                    print("\nğŸ“Š Usage Statistics:")
                    print(f"  ğŸ“ˆ Questions Asked: {question_count}")
                    print(f"  ğŸ’° Total Cost: $0.00 (FREE!)")
                    print(f"  ğŸ¤– Model: Groq Llama-3.1-8B")
                    print(f"  ğŸ”¤ Token Optimization: Enabled")
                    continue
                
                # Show debug info
                if question.lower() == 'debug':
                    print("\nğŸ”§ Token Optimization Details:")
                    print("  1ï¸âƒ£ Context limited to 3,000 tokens (top 3 chunks)")
                    print("  2ï¸âƒ£ Code examples removed (saves 50-70% tokens)")
                    print("  3ï¸âƒ£ Key sentences extracted with keyword prioritization")
                    print("  4ï¸âƒ£ Smart truncation preserves sentence boundaries")
                    print("  âš¡ Emergency truncation at 5,500 tokens")
                    print("  ğŸ¯ Target: Under 6,000 token Groq FREE tier limit")
                    continue
                
                # Answer the question with token optimization
                question_count += 1
                print(f"\nğŸ¤– Thinking... (Question #{question_count})")
                start = time.time()
                
                # Retrieve relevant chunks
                print("ğŸ” Searching knowledge base...")
                chunks = retrieve_relevant_chunks(question, num_chunks=5)
                
                if not chunks:
                    print("âŒ No relevant information found. Try rephrasing your question.")
                    continue
                
                print(f"ğŸ“š Found {len(chunks)} relevant document(s)")
                
                # Generate answer with optimized Groq system
                print("ğŸ¤– Generating answer with Groq AI (FREE!)...")
                response = generate_groq_answer(question, chunks)
                
                print(f"\nğŸ’¡ Answer:")
                # Clean up the answer to remove URLs from source citations
                answer = response.get('answer', 'No answer generated')
                cleaned_answer = self._clean_source_citations(answer)
                print(cleaned_answer)
                
                # Show token usage and performance details
                print(f"\nğŸ“Š Performance Details:")
                print(f"  âš¡ Response Time: {response.get('response_time', format_time_elapsed(start))}")
                print(f"  ğŸ”¤ Tokens Used: {response.get('token_count', 'Unknown')}")
                print(f"  ğŸ’° Cost: {response.get('cost', '$0.00 (FREE!)')}")
                print(f"  ğŸ¤– Model: {response.get('method', 'Groq Llama-3.1-8B')}")
                
                # Show sources if available
                sources = response.get("sources", [])
                if sources:
                    print(f"ğŸ“š Sources:")
                    for i, source in enumerate(sources, 1):
                        if source and source != "Unknown":
                            print(f"  {i}. {source}")
                
                elapsed = format_time_elapsed(start)
                print(f"\nâ±ï¸ Total processing time: {elapsed}")
                
            except KeyboardInterrupt:
                print("\n\nğŸ‘‹ Goodbye!")
                break
            except Exception as e:
                print(f"\nâŒ Error: {str(e)}")
                continue
        
        print(f"\nğŸ“Š Session summary: Answered {question_count} questions")
    
    def generate_content_summary(self):
        """Generates a summary of the loaded content."""
        print("\nğŸ“ CONTENT SUMMARY")
        print("-" * 40)
        
        try:
            data_dir = "data"
            if not os.path.exists(data_dir):
                print("âŒ No content loaded. Please run document ingestion first.")
                return
            
            chunk_files = [f for f in os.listdir(data_dir) if f.endswith('.txt')]
            if not chunk_files:
                print("âŒ No documents found in data directory.")
                return
            
            print(f"ğŸ“Š Total Documents: {len(chunk_files)} chunks")
            
            # Combine first few chunks for summary
            content_sample = ""
            for i, filename in enumerate(chunk_files[:3]):  # First 3 chunks
                try:
                    with open(os.path.join(data_dir, filename), 'r', encoding='utf-8', errors='ignore') as f:
                        content = f.read()
                        content_sample += content[:500] + " "  # First 500 chars of each
                except:
                    continue
            
            if content_sample:
                # Extract key topics from content
                words = content_sample.lower().split()
                # Simple keyword extraction
                common_tech_words = ['algorithm', 'data', 'structure', 'graph', 'tree', 'node', 'vertex', 'edge', 
                                   'python', 'programming', 'function', 'method', 'class', 'object', 'web', 'html', 
                                   'css', 'javascript', 'database', 'sql', 'machine', 'learning', 'ai', 'model']
                
                found_topics = [word for word in set(words) if word in common_tech_words and len(word) > 3]
                
                print(f"ğŸ” Key Topics Detected:")
                if found_topics:
                    for topic in sorted(found_topics)[:10]:
                        print(f"  â€¢ {topic.capitalize()}")
                else:
                    print("  â€¢ General technical documentation")
                
                # Quick content preview
                print(f"\nğŸ“– Content Preview:")
                preview = content_sample[:300].replace('\n', ' ').strip()
                if len(preview) > 297:
                    preview = preview[:297] + "..."
                print(f"   {preview}")
                
            print(f"\nğŸ’¡ Ask specific questions about these topics for detailed answers.")
            
        except Exception as e:
            print(f"âŒ Error generating summary: {str(e)}")
    
    def show_faq(self):
        """Shows FAQ questions based on the loaded content."""
        print("\nâ“ FREQUENTLY ASKED QUESTIONS")
        print("-" * 40)
        
        try:
            # Generate dynamic FAQ based on content
            faq_questions = self._generate_dynamic_faq()
            
            if faq_questions:
                print("Here are some questions you can ask based on your content:\n")
                for i, question in enumerate(faq_questions, 1):
                    print(f"{i}. {question}")
                
                print(f"\nğŸ’¡ Tip: Copy and paste any question above to get a detailed answer!")
            else:
                print("âŒ Could not generate FAQ. Please ensure documents are loaded.")
                
        except Exception as e:
            print(f"âŒ Error generating FAQ: {str(e)}")
    
    def _generate_dynamic_faq(self) -> List[str]:
        """Generate FAQ questions based on the actual content."""
        try:
            data_dir = "data"
            if not os.path.exists(data_dir):
                return []
            
            # Analyze content from data directory
            content_sample = ""
            chunk_files = [f for f in os.listdir(data_dir) if f.endswith('.txt')][:3]
            
            for filename in chunk_files:
                try:
                    with open(os.path.join(data_dir, filename), 'r', encoding='utf-8', errors='ignore') as f:
                        content_sample += f.read().lower()[:800]  # First 800 chars per file
                except:
                    continue
            
            # Generate questions based on content analysis
            if 'graph' in content_sample:
                return [
                    "What is a graph data structure?",
                    "How are graphs different from trees?",
                    "What are the applications of graphs?",
                    "What is BFS and DFS in graphs?",
                    "How do you represent a graph?",
                    "What are the types of graph algorithms?"
                ]
            elif 'machine learning' in content_sample or 'algorithm' in content_sample:
                return [
                    "What is machine learning?",
                    "What are the types of machine learning algorithms?",
                    "How does supervised learning work?",
                    "What is the difference between classification and regression?",
                    "What are common machine learning algorithms?",
                    "What are some applications of Self-Supervised Learning?",
                    "How do you evaluate machine learning models?"
                ]
            elif 'python' in content_sample and 'programming' in content_sample:
                return [
                    "How do you define a function in Python?",
                    "What are Python data types?",
                    "How to handle exceptions in Python?",
                    "What is the difference between lists and tuples?",
                    "How to work with files in Python?",
                    "What are Python modules and packages?"
                ]
            elif 'web' in content_sample or 'html' in content_sample:
                return [
                    "How does HTML structure web pages?",
                    "What are CSS selectors and properties?",
                    "How does JavaScript add interactivity?",
                    "What are responsive design principles?",
                    "How to optimize web page performance?",
                    "What are web accessibility best practices?"
                ]
            elif 'database' in content_sample or 'sql' in content_sample:
                return [
                    "What are the fundamental database concepts?",
                    "How do SQL queries work?",
                    "What are database relationships?",
                    "How to optimize database performance?",
                    "What are database normalization principles?",
                    "How to handle database transactions?"
                ]
            else:
                # Generic questions for any documentation
                return [
                    "What is the main topic explained in this documentation?",
                    "Can you provide an overview of the key concepts?",
                    "What are the main features described?",
                    "What are the practical applications?",
                    "How does this technology work?",
                    "What are the benefits and advantages?"
                ]
                
        except Exception as e:
            # Fallback questions
            return [
                "What is the main topic explained in this documentation?",
                "Can you provide an overview of the key concepts?",
                "What are the practical applications?",
                "How does this technology work?",
                "What are the benefits and advantages?"
            ]
    
    def show_help(self):
        """Shows help with dynamic sample questions based on content."""
        print("\nğŸ“‹ SAMPLE QUESTIONS TO TRY:")
        print("-" * 40)
        
        # Generate dynamic questions based on actual content
        sample_questions = self._generate_dynamic_questions()
        
        for i, question in enumerate(sample_questions, 1):
            print(f"{i}. {question}")
        
        print("\nğŸ’¡ Tips:")
        print("- Ask specific questions about the topics in your documentation")
        print("- Questions should relate to the documentation you provided")
        print("- If information isn't in the docs, I'll tell you honestly")
        print("- System uses FREE Groq API with token optimization")
        print("- Each answer costs $0.00 and responds in ~2-3 seconds")
    
    def _generate_dynamic_questions(self) -> List[str]:
        """Generate sample questions based on the actual content."""
        try:
            # Analyze content from data directory to generate relevant questions
            content_sample = ""
            data_dir = "data"
            
            if os.path.exists(data_dir):
                chunk_files = [f for f in os.listdir(data_dir) if f.endswith('.txt')][:3]
                
                for filename in chunk_files:
                    try:
                        with open(os.path.join(data_dir, filename), 'r', encoding='utf-8', errors='ignore') as f:
                            content_sample += f.read().lower()[:1000]  # Sample first 1000 chars
                    except:
                        continue
            
            # Generate questions based on content type
            if 'machine learning' in content_sample or 'supervised' in content_sample:
                return [
                    "What is supervised machine learning?",
                    "What are the types of supervised learning?", 
                    "How does classification differ from regression?",
                    "What is the training process in supervised learning?",
                    "What are common supervised learning algorithms?",
                    "How do you evaluate a supervised learning model?",
                ]
            elif 'python' in content_sample and 'programming' in content_sample:
                return [
                    "How do you define a function in Python?",
                    "What are Python data types?",
                    "How to handle exceptions in Python?",
                    "What is the difference between lists and tuples?",
                    "How to work with files in Python?",
                    "What are Python modules and packages?",
                ]
            elif 'web' in content_sample or 'html' in content_sample or 'css' in content_sample:
                return [
                    "How does HTML structure web pages?",
                    "What are CSS selectors and properties?",
                    "How does JavaScript add interactivity?",
                    "What are responsive design principles?",
                    "How to optimize web page performance?",
                    "What are web accessibility best practices?",
                ]
            elif 'database' in content_sample or 'sql' in content_sample:
                return [
                    "What are the fundamental database concepts?",
                    "How do SQL queries work?",
                    "What are database relationships?",
                    "How to optimize database performance?",
                    "What are database normalization principles?",
                    "How to handle database transactions?",
                ]
            else:
                # Universal questions that work for any type of documentation
                return [
                    "What is the main topic or concept explained?",
                    "Can you provide a summary?",
                    "What are the key features or characteristics?",
                    "What are the main benefits and advantages?",
                    "What are the common use cases or applications?",
                    "How does this work or function?",
                ]
                
        except Exception as e:
            # Fallback to universal questions
            return [
                "What is the main topic or concept explained?",
                "Can you provide a summary?",
                "What are the key features or characteristics?",
                "What are the main benefits and advantages?",
                "What are the common use cases or applications?",
                "How does this work or function?",
            ]
    
    def _clean_source_citations(self, answer: str) -> str:
        """Clean source citations to remove URLs and keep only chunk information."""
        import re
        
        # Pattern to match: (Source: https://any-url/ Chunk X/Y)
        # Replace with: (Chunk X/Y)
        pattern = r'\(Source:\s*https?://[^\s)]+\s+(Chunk\s+\d+/\d+)\)'
        cleaned = re.sub(pattern, r'(\1)', answer)
        
        # Also handle cases where Source: is at the beginning of a line
        pattern2 = r'^Source:\s*https?://[^\s]+\s+(Chunk\s+\d+/\d+)'
        cleaned = re.sub(pattern2, r'(\1)', cleaned, flags=re.MULTILINE)
        
        # Handle cases with "Source:" followed by URL and chunk on separate lines
        pattern3 = r'Source:\s*\[?Source\s*\d*:\s*https?://[^\]]+\s+(Chunk\s+\d+/\d+)\]?'
        cleaned = re.sub(pattern3, r'(\1)', cleaned)
        
        return cleaned
    
    def show_final_summary(self):
        """Shows final summary of the session."""
        total_time = format_time_elapsed(self.start_time)
        
        print("\n" + "="*70)
        print("ğŸ‰ KNOWLEDGE ASSISTANT SESSION COMPLETE")
        print("="*70)
        print(f"â±ï¸ Total runtime: {total_time}")
        print(f"ğŸ“„ URLs processed: {len(self.processed_urls)}")
        
        print(f"ğŸ§  Vector database: {'Ready' if self.vector_db_ready else 'Failed'}")
        print(f"ğŸ¤– Groq AI: FREE tier with token optimization")
        print(f"ğŸ’° Total cost: $0.00")
        
        print("\nğŸ“ Generated files:")
        files_to_check = [
            ("faiss_index/", "FAISS vector database"),
        ]
        
        for filepath, description in files_to_check:
            if os.path.exists(filepath):
                print(f"   âœ… {filepath} - {description}")
            else:
                print(f"   âŒ {filepath} - {description} (not created)")
        
        print("\nğŸ”„ To run again: python main.py")
        print("ğŸ‘‹ Thank you for using the Enterprise Knowledge Assistant!")
    
    def run(self):
        """Main execution method."""
        try:
            # Welcome
            self.print_welcome()
            
            # Step 1: Get URLs
            urls = self.get_documentation_urls()
            
            # Step 2: Ingest documentation
            if not self.run_ingestion(urls):
                print("âŒ Cannot continue without successful ingestion")
                return
            
            # Step 3: Build vector database
            if not self.build_vector_database():
                print("âŒ Cannot continue without vector database")
                return
            
            # Step 4: Interactive Q&A
            self.interactive_qa_mode()
            
        except KeyboardInterrupt:
            print("\n\nâš ï¸ Process interrupted by user")
        except Exception as e:
            print(f"\nâŒ Unexpected error: {str(e)}")
            print("ğŸ“ Please check the error and try again")
        finally:
            # Always show summary
            self.show_final_summary()


def main():
    """Main function - entry point of the application."""
    assistant = KnowledgeAssistant()
    assistant.run()


# Run the application
if __name__ == "__main__":
    main()